const {
	Aborter,
	BlockBlobURL,
	ContainerURL,
	ServiceURL,
	SharedKeyCredential,
	StorageURL,
	uploadStreamToBlockBlob,
} = require("@azure/storage-blob");

const fs = require("fs");
const path = require("path");

if (process.env.NODE_ENV !== "production") {
	require("dotenv").config();
}

const STORAGE_ACCOUNT_NAME = process.env.AZURE_STORAGE_ACCOUNT_NAME;
const ACCOUNT_ACCESS_KEY = process.env.AZURE_STORAGE_ACCOUNT_ACCESS_KEY;
const CONTAINER_NAME = process.env.CONTAINER_NAME;

const ONE_MEGABYTE = 1024 * 1024;
const FOUR_MEGABYTES = 4 * ONE_MEGABYTE;
const ONE_MINUTE = 60 * 1000;

async function uploadStream(aborter, containerURL, filePath) {
	filePath = path.resolve(filePath);

	const fileName = path.basename(filePath)
	const blockBlobURL = BlockBlobURL.fromContainerURL(containerURL, fileName);

	const stream = fs.createReadStream(filePath, {
		highWaterMark: FOUR_MEGABYTES
	});

	const uploadOptions = {
		bufferSize: FOUR_MEGABYTES,
		maxBuffers: 5
  };
  
	return await uploadStreamToBlockBlob(
		aborter,
		stream,
		blockBlobURL,
		uploadOptions.bufferSize,
		uploadOptions.maxBuffers
	);
}

exports.uploadFileToContainer = async (filePath) => {
  const containerName = CONTAINER_NAME;

	const credentials = new SharedKeyCredential(
		STORAGE_ACCOUNT_NAME,
		ACCOUNT_ACCESS_KEY
	);
	const pipeline = StorageURL.newPipeline(credentials);
	const serviceURL = new ServiceURL(
		`https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net`,
		pipeline
	);

	const containerURL = ContainerURL.fromServiceURL(serviceURL, containerName);

	const aborter = Aborter.timeout(30 * ONE_MINUTE);

  const result = await uploadStream(aborter, containerURL, filePath);
  console.log(`Local file "${filePath}" is uploaded as a stream`);
  return true;

}